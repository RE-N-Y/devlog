title: "TextMI: Textualize Multimodal Information for Integrating Non-verbal Cues in Pre-trained Language Models"
authors:
  - name: "Md Kamrul Hasan"
    order: 1
  - name: "Md Saiful Islam"
    order: 2
  - name: "Sangwu Lee"
    order: 3
    me: true
  - name: "Wasifur Rahman"
    order: 4
  - name: "Iftekhar Naim"
    order: 5
  - name: "Mohammed Ibrahim Khan"
    order: 6
  - name: "Ehsan Hoque"
    order: 7
link: "https://arxiv.org/pdf/2303.15430.pdf"
abstract: "Pre-trained large language models have recently achieved ground-breaking performance in a wide variety of language understanding tasks. However, the same model can not be applied to multimodal behavior understanding tasks (e.g., video sentiment/humor detection) unless non-verbal features (e.g., acoustic and visual) can be integrated with language. Jointly modeling multiple modalities significantly increases the model complexity, and makes the training process data-hungry. While an enormous amount of text data is available via the web, collecting large-scale multimodal behavioral video datasets is extremely expensive, both in terms of time and money. In this paper, we investigate whether large language models alone can successfully incorporate non-verbal information when they are presented in textual form. We present a way to convert the acoustic and visual information into corresponding textual descriptions and concatenate them with the spoken text. We feed this augmented input to a pre-trained BERT model and fine-tune it on three downstream multimodal tasks: sentiment, humor, and sarcasm detection. Our approach, TextMI, significantly reduces model complexity, adds interpretability to the model's decision, and can be applied for a diverse set of tasks while achieving superior (multimodal sarcasm detection) or near SOTA (multimodal sentiment analysis and multimodal humor detection) performance. We propose TextMI as a general, competitive baseline for multimodal behavioral analysis tasks, particularly in a low-resource setting."
publisher: "arXiv preprint"
pubDate: 2021-03-29
